{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff72567c",
   "metadata": {},
   "source": [
    "\n",
    "# Build a best machine learining model to predict the right real estate price for the property owners.\n",
    "    \n",
    "## Project description :\n",
    "\n",
    "Imagine that we work for a real estate platform. Instead of using real estate agent services, property owners submit their own listings, and buyers can respond to them directly. If a transaction goes through successfully, the platform takes a cut.\n",
    "Website analytics showed that property owners often fail to base their prices on the market value. This practice is always bad for the website: inexpensive items are sold quickly, but the platform's cut is also lower because of this. Overpriced items, on the other hand, are never sold, which means no profit at all. The service needs to prevent sellers from underselling and overpricing. We need to figure out an algorithm to help property owners determine the right price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bfcbe8",
   "metadata": {},
   "source": [
    "## Description of the data :\n",
    "\n",
    "For this task, we are going to use the data presented by an online real estate market. To make it suitable for model training, we have deleted the variables that don't affect the price, as well as missing values and apartments outside the city limits. The file name is train_data_us.csv and  contains the following columns:\n",
    "\n",
    "\n",
    "1. last_price — price at listing closure (in dollars)\n",
    "1. total_area — apartment area in square meters (m²)\n",
    "1. bedrooms — number of bedrooms\n",
    "1. ceiling_height — ceiling height (m)\n",
    "1. floors_total — total number of floors\n",
    "1. living_area — living area (m²)\n",
    "1. floor — floor\n",
    "1. bike_parking — bike parking in the building (Boolean data type)\n",
    "1. is_studio — studio (Boolean data type)\n",
    "1. is_open_plan — open plan (Boolean data type)\n",
    "1. kitchen_area — kitchen area (m²)\n",
    "1. balconies — number of balconies\n",
    "1. airport_dist — distance to the nearest airport in meters (m)\n",
    "1. city_center_dist — distance to the city center (m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb40c4",
   "metadata": {},
   "source": [
    "\n",
    "## Outline\n",
    "\n",
    "### Task:\n",
    "\n",
    "Use classification and regression models and find the best perfomance model.\n",
    "\n",
    "<img src=\"diagram.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e8bf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>kitchen_area</th>\n",
       "      <th>living_area</th>\n",
       "      <th>total_area</th>\n",
       "      <th>balconies</th>\n",
       "      <th>ceiling_height</th>\n",
       "      <th>floors_total</th>\n",
       "      <th>floor</th>\n",
       "      <th>bike_parking</th>\n",
       "      <th>is_studio</th>\n",
       "      <th>is_open_plan</th>\n",
       "      <th>airport_dist</th>\n",
       "      <th>city_center_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>31.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.87</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20485</td>\n",
       "      <td>8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>264000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42683</td>\n",
       "      <td>8643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14078</td>\n",
       "      <td>16670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17792</td>\n",
       "      <td>17699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>41.9</td>\n",
       "      <td>64.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14767</td>\n",
       "      <td>10573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_price  bedrooms  kitchen_area  living_area  total_area  balconies  \\\n",
       "0    108000.0         2           6.6         31.5        59.0          0   \n",
       "1    264000.0         4          12.2         72.0       109.0          0   \n",
       "2    140000.0         3          10.8         49.0        74.5          0   \n",
       "3     64000.0         1           6.2         20.0        37.4          2   \n",
       "4    133000.0         3          10.4         41.9        64.9          0   \n",
       "\n",
       "   ceiling_height  floors_total  floor  bike_parking  is_studio  is_open_plan  \\\n",
       "0            2.87             4      2             0          0             0   \n",
       "1            3.15             5      2             0          0             0   \n",
       "2            2.58            10      9             0          0             0   \n",
       "3            2.50             9      4             0          0             0   \n",
       "4            2.65            12     11             0          0             0   \n",
       "\n",
       "   airport_dist  city_center_dist  \n",
       "0         20485              8180  \n",
       "1         42683              8643  \n",
       "2         14078             16670  \n",
       "3         17792             17699  \n",
       "4         14767             10573  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6495 entries, 0 to 6494\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   last_price        6495 non-null   float64\n",
      " 1   bedrooms          6495 non-null   int64  \n",
      " 2   kitchen_area      6495 non-null   float64\n",
      " 3   living_area       6495 non-null   float64\n",
      " 4   total_area        6495 non-null   float64\n",
      " 5   balconies         6495 non-null   int64  \n",
      " 6   ceiling_height    6495 non-null   float64\n",
      " 7   floors_total      6495 non-null   int64  \n",
      " 8   floor             6495 non-null   int64  \n",
      " 9   bike_parking      6495 non-null   int64  \n",
      " 10  is_studio         6495 non-null   int64  \n",
      " 11  is_open_plan      6495 non-null   int64  \n",
      " 12  airport_dist      6495 non-null   int64  \n",
      " 13  city_center_dist  6495 non-null   int64  \n",
      "dtypes: float64(5), int64(9)\n",
      "memory usage: 710.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train_data_us.csv')\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e12b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average apartment price: 161005.67427559663\n"
     ]
    }
   ],
   "source": [
    "print('Average apartment price:',df['last_price'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c387fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median apertment price: 113000.0\n"
     ]
    }
   ],
   "source": [
    "print('Median apertment price:',df['last_price'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0729782",
   "metadata": {},
   "source": [
    "* Conclusion:\n",
    "\n",
    "As we have some very large price, so it will not give us actual average price in general.So, we took the median price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345ff4a",
   "metadata": {},
   "source": [
    "Apartment price is a numerical target, so this is a regression task. Regression usually involves lengthy calculations with many possible answers, so regression tasks aren't the easiest way to get acquainted with machine learning. For simplicity's sake, we'll split all prices into \"high\" and \"low\" for now, effectively turning our task into a binary classification task with only two possible answers. Then all we have to do is predict which class any given listing falls into. We'll deal with regression later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9bfbd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>kitchen_area</th>\n",
       "      <th>living_area</th>\n",
       "      <th>total_area</th>\n",
       "      <th>balconies</th>\n",
       "      <th>ceiling_height</th>\n",
       "      <th>floors_total</th>\n",
       "      <th>floor</th>\n",
       "      <th>bike_parking</th>\n",
       "      <th>is_studio</th>\n",
       "      <th>is_open_plan</th>\n",
       "      <th>airport_dist</th>\n",
       "      <th>city_center_dist</th>\n",
       "      <th>price_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>31.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.87</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20485</td>\n",
       "      <td>8180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>264000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42683</td>\n",
       "      <td>8643</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14078</td>\n",
       "      <td>16670</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17792</td>\n",
       "      <td>17699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>41.9</td>\n",
       "      <td>64.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14767</td>\n",
       "      <td>10573</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_price  bedrooms  kitchen_area  living_area  total_area  balconies  \\\n",
       "0    108000.0         2           6.6         31.5        59.0          0   \n",
       "1    264000.0         4          12.2         72.0       109.0          0   \n",
       "2    140000.0         3          10.8         49.0        74.5          0   \n",
       "3     64000.0         1           6.2         20.0        37.4          2   \n",
       "4    133000.0         3          10.4         41.9        64.9          0   \n",
       "\n",
       "   ceiling_height  floors_total  floor  bike_parking  is_studio  is_open_plan  \\\n",
       "0            2.87             4      2             0          0             0   \n",
       "1            3.15             5      2             0          0             0   \n",
       "2            2.58            10      9             0          0             0   \n",
       "3            2.50             9      4             0          0             0   \n",
       "4            2.65            12     11             0          0             0   \n",
       "\n",
       "   airport_dist  city_center_dist  price_class  \n",
       "0         20485              8180          0.0  \n",
       "1         42683              8643          1.0  \n",
       "2         14078             16670          1.0  \n",
       "3         17792             17699          0.0  \n",
       "4         14767             10573          1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['price_class'] = df['last_price']\n",
    "df.loc[df['last_price'] > 113000,'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000,'price_class'] = 0\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c3d07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6495, 13)\n",
      "(6495,)\n"
     ]
    }
   ],
   "source": [
    "features = df.loc[:, ~df.columns.isin(['last_price','price_class'])]\n",
    "target = df['price_class']\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c01518",
   "metadata": {},
   "source": [
    "### Checking model perfomance DecisionTreeClassifier / RandomForestClassifier / LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a6f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score , f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f2336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data_us.csv')\n",
    "df['price_class'] = df['last_price']\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "# < split data into training and validation >\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345) \n",
    "\n",
    "# < declare variables for features and target feature >\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae820d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4871, 13)\n",
      "(4871,)\n",
      "(1624, 13)\n",
      "(1624,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504b021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler object and apply it to train set\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train scaler and transform the matric for train set\n",
    "features_train_st = scaler.fit_transform(features_train)\n",
    "\n",
    "# apply standardization of feature matric for test set\n",
    "features_valid_st = scaler.transform(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ee70925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  DecisionTreeClassifier(max_depth=5, random_state=12345)\n",
      "Accuracy: 0.87\n",
      "Precision: 0.85\n",
      "Recall: 0.88\n",
      "F1: 0.86\n",
      "\n",
      "\n",
      "Model:  RandomForestClassifier(n_estimators=5, random_state=12345)\n",
      "Accuracy: 0.88\n",
      "Precision: 0.87\n",
      "Recall: 0.88\n",
      "F1: 0.88\n",
      "\n",
      "\n",
      "Model:  LogisticRegression(random_state=12345, solver='liblinear')\n",
      "Accuracy: 0.89\n",
      "Precision: 0.90\n",
      "Recall: 0.87\n",
      "F1: 0.88\n",
      "\n",
      "\n",
      "Mean: 0.49\n"
     ]
    }
   ],
   "source": [
    "# define the models to compare\n",
    "models = [DecisionTreeClassifier(random_state=12345, max_depth=5), RandomForestClassifier(random_state=12345, n_estimators=5),LogisticRegression(random_state=12345, solver='liblinear')]\n",
    "\n",
    "# function that predicts model by taking data as input and outputting metrics\n",
    "def make_prediction(model, features_train, target_train, features_valid, target_valid):\n",
    "    model = model\n",
    "    model.fit(features_train_st, target_train)\n",
    "    predictions = model.predict(features_valid_st)\n",
    "    print('Model: ', model)\n",
    "    print('Accuracy: {:.2f}'.format(accuracy_score(target_valid , predictions)))\n",
    "    print('Precision: {:.2f}'.format(precision_score(target_valid , predictions)))\n",
    "    print('Recall: {:.2f}'.format(recall_score(target_valid , predictions)))\n",
    "    print('F1: {:.2f}'.format(f1_score(target_valid, predictions)))\n",
    "    print('\\n')\n",
    "\n",
    "# output metric for both models\n",
    "for i in models:\n",
    "    make_prediction(i, features_train, target_train, features_valid, target_valid)\n",
    "    \n",
    "print('Mean: {:.2f}'.format(target_valid.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074be8cd",
   "metadata": {},
   "source": [
    "Accuracy - Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. One may think that, if we have high accuracy then our model is best. Yes, accuracy is a great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same. Therefore, you have to look at other parameters to evaluate the performance of your model. For example, we have got 0.803 which means our model is approx. 80% accurate.\n",
    "\n",
    "Accuracy = TP+TN/TP+FP+FN+TN\n",
    "\n",
    "Precision - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answer is of all passengers that labeled as survived, how many actually survived? High precision relates to the low false positive rate.For example, if we have got 0.788 precision which is pretty good.\n",
    "\n",
    "Precision = TP/TP+FP\n",
    "\n",
    "Recall (Sensitivity) - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. The question recall answers is: Of all the passengers that truly survived, how many did we label? For example, If We got recall of 0.631 which is good for this model as it’s above 0.5.\n",
    "\n",
    "Recall = TP/TP+FN\n",
    "\n",
    "F1 score - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall. \n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2906bbbf",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14cad81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator = 1 : 0.8491379310344828\n",
      "estimator = 2 : 0.8448275862068966\n",
      "estimator = 3 : 0.8737684729064039\n",
      "estimator = 4 : 0.8793103448275862\n",
      "estimator = 5 : 0.8830049261083743\n",
      "estimator = 6 : 0.8928571428571429\n",
      "estimator = 7 : 0.8934729064039408\n",
      "estimator = 8 : 0.8922413793103449\n",
      "estimator = 9 : 0.895320197044335\n",
      "estimator = 10 : 0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "#if we want get improve perfomanece:\n",
    "# < create a loop for estimator from 1 to 11>\n",
    "for estimator in range(1, 11):\n",
    "       model = RandomForestClassifier(random_state=12345, n_estimators=estimator) \n",
    "\n",
    "        # < train the model >\n",
    "       model.fit(features_train, target_train)\n",
    "       predictions = model.predict(features_valid)\n",
    "       score =  accuracy_score(target_valid , predictions) \n",
    "       print(\"estimator =\", estimator, \": \", end='')\n",
    "       print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede9f04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = 1 : 0.8522167487684729\n",
      "depth = 2 : 0.8522167487684729\n",
      "depth = 3 : 0.8466748768472906\n",
      "depth = 4 : 0.8725369458128078\n",
      "depth = 5 : 0.8663793103448276\n",
      "depth = 6 : 0.8706896551724138\n",
      "depth = 7 : 0.8663793103448276\n",
      "depth = 8 : 0.8725369458128078\n",
      "depth = 9 : 0.8657635467980296\n",
      "depth = 10 : 0.8608374384236454\n"
     ]
    }
   ],
   "source": [
    "#if we want get improve perfomanece:\n",
    "# < create a loop for depth from 1 to 11>\n",
    "for depth in range(1, 11):\n",
    "       model = DecisionTreeClassifier(max_depth=depth, random_state=12345) \n",
    "\n",
    "        # < train the model >\n",
    "       model.fit(features_train, target_train)\n",
    "       predictions = model.predict(features_valid)\n",
    "       score =  accuracy_score(target_valid , predictions) \n",
    "       print(\"depth =\", depth, \": \", end='')\n",
    "       print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eccfc70",
   "metadata": {},
   "source": [
    "<img src=\"diagram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d5d5d",
   "metadata": {},
   "source": [
    "* Conclusion :\n",
    "\n",
    "1. There is no specific rules which model we should use.It depends on the job need.Even though the name logistic regression is suggestive of a regression problem, it is still a classification algorithm.\n",
    "\n",
    "2. Comparing three model,random forest have the highest accuracy and low speed.Logistic regression works as moderate level.Sometimes, hyper parater tuning helps a lot to improve model perfomance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ecd5a",
   "metadata": {},
   "source": [
    "### Check model works or not?\n",
    "\n",
    "Create two new observations and check the prediction results. Remember that everything above and below the median price was labeled with price classes 1 and 0 respectively. The observations in our task are apartments. Write down the values of the features for each observation:\n",
    "1.\tThe first apartment has 12 bedrooms with a total area of 900 m². The living area is 409.7 m², and the kitchen area is 112 m².\n",
    "2.\tThe second apartment has 2 bedrooms with a total area of 109 m². The living area is 32 m², and the kitchen area is 40.5 m²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d2a3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = pd.DataFrame(\n",
    "    [\n",
    "        [None, None, None, None, 0, 2.8, 25, 25, 0, 0, 0, 30706.0, 7877.0],\n",
    "        [None, None, None, None, 0, 2.75, 25, 25, 0, 0, 0, 36421.0, 9176.0],\n",
    "    ],\n",
    "    columns=features.columns,\n",
    ")\n",
    "\n",
    "# complete the table with the new features\n",
    "new_features.loc[0, 'bedrooms'] = 12\n",
    "new_features.loc[0, 'kitchen_area'] = 112\n",
    "new_features.loc[0, 'living_area'] = 409.7\n",
    "new_features.loc[0, 'total_area'] = 900\n",
    "new_features.loc[1, 'bedrooms'] = 2\n",
    "new_features.loc[1, 'kitchen_area'] = 40.5\n",
    "new_features.loc[1, 'living_area'] = 32\n",
    "new_features.loc[1, 'total_area'] = 109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7a9b04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# predict answers and print the result on the screen\n",
    "answers = model.predict(new_features) \n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ecd50",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "The model confidently puts the luxurious twelve bedrooms apartment into the expensive class,while a tiny two bedrooms is obviously is a cheap dwelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7d97d",
   "metadata": {},
   "source": [
    "## Regression task:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c6cc3",
   "metadata": {},
   "source": [
    "A decision tree can be used for regression just as well as for classification.\n",
    "For a regression task, the decision tree is trained in a manner similar to classification, but it predicts a \n",
    "number instead of a class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d067010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "816e3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data_us.csv')\n",
    "df['price_class'] = df['last_price']\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "# < split data into training and validation >\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345) \n",
    "\n",
    "# < declare variables for features and target feature >\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6100bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4871, 13)\n",
      "(4871,)\n",
      "(1624, 13)\n",
      "(1624,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d66c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data_us.csv')\n",
    "df['price_class']=df['last_price']\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f28fe77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler object and apply it to train set\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train scaler and transform the matric for train set\n",
    "features_train_st = scaler.fit_transform(features_train)\n",
    "\n",
    "# apply standardization of feature matric for test set\n",
    "features_valid_st = scaler.transform(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f10f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso()\n",
      "MAE:0.50 MSE:0.25 RMSE:0.50 MAPE:0.00 R2:-0.00 \n",
      "\n",
      "\n",
      "Ridge()\n",
      "MAE:0.33 MSE:0.15 RMSE:0.38 MAPE:0.00 R2:0.41 \n",
      "\n",
      "\n",
      "DecisionTreeRegressor()\n",
      "MAE:0.15 MSE:0.15 RMSE:0.39 MAPE:0.00 R2:0.39 \n",
      "\n",
      "\n",
      "RandomForestRegressor()\n",
      "MAE:0.15 MSE:0.08 RMSE:0.28 MAPE:0.00 R2:0.69 \n",
      "\n",
      "\n",
      "GradientBoostingRegressor()\n",
      "MAE:0.16 MSE:0.08 RMSE:0.27 MAPE:0.00 R2:0.70 \n",
      "\n",
      "\n",
      "Mean: 0.49\n"
     ]
    }
   ],
   "source": [
    "# declare the list of models\n",
    "models = [Lasso(), Ridge(), DecisionTreeRegressor(), RandomForestRegressor(), GradientBoostingRegressor()]\n",
    "\n",
    "# the function that calculates MAPE\n",
    "def mape(y_true, y_pred):\n",
    "    y_error = y_true - y_pred\n",
    "    y_error_abs = abs(y_error)\n",
    "    perc_error_abs = y_error_abs / y_true\n",
    "    mape = (perc_error_abs.sum()/len(y_true))\n",
    "    return mape\n",
    "\n",
    "# the function that takes the model and data as input and outputs metrics\n",
    "def make_prediction(model, features_train, target_train, features_valid, target_valid):\n",
    "    model = model\n",
    "    model.fit(features_train_st, target_train)\n",
    "    predictions = model.predict(features_valid_st)\n",
    "    MAE = mean_absolute_error(target_valid, predictions)\n",
    "    MSE = mean_squared_error(target_valid, predictions)\n",
    "    MAPE = mape(target_train, target_valid)\n",
    "    R2 = r2_score(target_valid, predictions)\n",
    "    RMSE = MSE ** 0.5\n",
    "    print('MAE:{:.2f} MSE:{:.2f} RMSE:{:.2f} MAPE:{:.2f} R2:{:.2f} '.format(MAE, MSE, RMSE, MAPE, R2))\n",
    "    print('\\n')\n",
    "\n",
    "# write a loop that outputs metrics for each model\n",
    "for i in models:\n",
    "    print(i)\n",
    "    make_prediction(i, features_train, target_train, features_valid, target_valid)\n",
    "    \n",
    "# print the mean target variable value on the test set\n",
    "print('Mean: {:.2f}'.format(target_valid.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a943b120",
   "metadata": {},
   "source": [
    "The MSE, MAE, RMSE, and R-Squared metrics are mainly used to evaluate the prediction error rates and model performance in regression analysis.\n",
    "\n",
    "1. MAE (Mean absolute error): represents the difference between the original and predicted values extracted by averaged the absolute difference over the data set.\n",
    "1. MSE (Mean Squared Error) : represents the difference between the original and predicted values extracted by squared the average difference over the data set.\n",
    "1. RMSE (Root Mean Squared Error) is the error rate by the square root of MSE.\n",
    "1. R-squared (Coefficient of determination) represents the coefficient of how well the values fit compared to the original values. The value from 0 to 1 interpreted as percentages. The higher the value is, the better the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192344f0",
   "metadata": {},
   "source": [
    "Comparing all the model, GradientBoostingRegressor() model did really good work in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834daf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
